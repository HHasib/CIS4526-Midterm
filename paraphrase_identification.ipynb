{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a373c7",
   "metadata": {},
   "source": [
    "Initially, we import alll the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "7f2361f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19734ea0",
   "metadata": {},
   "source": [
    "We import the necessary files and process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "38834b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 323: expected 4 fields, saw 5\\nSkipping line 823: expected 4 fields, saw 5\\nSkipping line 909: expected 4 fields, saw 5\\nSkipping line 1013: expected 4 fields, saw 5\\nSkipping line 1084: expected 4 fields, saw 5\\nSkipping line 1097: expected 4 fields, saw 5\\nSkipping line 1141: expected 4 fields, saw 5\\nSkipping line 1267: expected 4 fields, saw 5\\nSkipping line 1418: expected 4 fields, saw 5\\nSkipping line 1486: expected 4 fields, saw 5\\nSkipping line 1557: expected 4 fields, saw 5\\nSkipping line 1675: expected 4 fields, saw 5\\nSkipping line 1747: expected 4 fields, saw 5\\nSkipping line 1801: expected 4 fields, saw 5\\nSkipping line 1870: expected 4 fields, saw 5\\nSkipping line 2025: expected 4 fields, saw 5\\nSkipping line 2102: expected 4 fields, saw 5\\nSkipping line 2371: expected 4 fields, saw 5\\nSkipping line 2799: expected 4 fields, saw 5\\nSkipping line 3016: expected 4 fields, saw 5\\nSkipping line 3104: expected 4 fields, saw 5\\nSkipping line 3317: expected 4 fields, saw 5\\nSkipping line 3387: expected 4 fields, saw 5\\nSkipping line 3470: expected 4 fields, saw 5\\nSkipping line 3651: expected 4 fields, saw 5\\nSkipping line 3835: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 79: expected 4 fields, saw 5\\nSkipping line 418: expected 4 fields, saw 5\\nSkipping line 607: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 170: expected 3 fields, saw 4\\nSkipping line 389: expected 3 fields, saw 4\\nSkipping line 631: expected 3 fields, saw 4\\nSkipping line 656: expected 3 fields, saw 4\\nSkipping line 695: expected 3 fields, saw 4\\nSkipping line 809: expected 3 fields, saw 4\\n'\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('train_with_label.txt',sep='\\t',header=None, error_bad_lines= False)\n",
    "df_test = pd.read_csv('dev_with_label.txt', sep='\\t',header=None, error_bad_lines= False)\n",
    "df_test_pred =pd.read_csv('test_without_label.txt', sep='\\t',header=None, error_bad_lines= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "b537b169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_id_0</td>\n",
       "      <td>This blackout was largely preventable ,  said...</td>\n",
       "      <td>This blackout was largely preventable ,  Ener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_id_1</td>\n",
       "      <td>The Denver-based natural gas producer and mark...</td>\n",
       "      <td>The natural gas producer and marketer said the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_id_2</td>\n",
       "      <td>The other 18 people inside the building - two ...</td>\n",
       "      <td>The other 18 people in the building , includin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_id_3</td>\n",
       "      <td>Billy Hodge , 11 , is engrossed with the Harry...</td>\n",
       "      <td>Indeed , the Harry Potter series stands in a c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_id_4</td>\n",
       "      <td>Families stuck on the highway remained in thei...</td>\n",
       "      <td>Families stuck on the highway were being urged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>test_id_995</td>\n",
       "      <td>Sen. Bob Graham , Florida Democrat , raised $ ...</td>\n",
       "      <td>Further back , Sen. Bob Graham of Florida repo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>test_id_996</td>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron 's numbers also marked the first quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>test_id_997</td>\n",
       "      <td>The momentum in the marketplace continues to ...</td>\n",
       "      <td>The momentum in the marketplace continues to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>test_id_998</td>\n",
       "      <td>It ends tonight ,  a grim Keanu Reeves announ...</td>\n",
       "      <td>Keanu Reeves and Hugo Weaving in a scene from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>test_id_999</td>\n",
       "      <td>The petition alleges that Huletts unfair sales...</td>\n",
       "      <td>Those unfair sales have damaged the US industr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>949 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0                                                  1  \\\n",
       "0      test_id_0   This blackout was largely preventable ,  said...   \n",
       "1      test_id_1  The Denver-based natural gas producer and mark...   \n",
       "2      test_id_2  The other 18 people inside the building - two ...   \n",
       "3      test_id_3  Billy Hodge , 11 , is engrossed with the Harry...   \n",
       "4      test_id_4  Families stuck on the highway remained in thei...   \n",
       "..           ...                                                ...   \n",
       "944  test_id_995  Sen. Bob Graham , Florida Democrat , raised $ ...   \n",
       "945  test_id_996  Micron has declared its first quarterly profit...   \n",
       "946  test_id_997   The momentum in the marketplace continues to ...   \n",
       "947  test_id_998   It ends tonight ,  a grim Keanu Reeves announ...   \n",
       "948  test_id_999  The petition alleges that Huletts unfair sales...   \n",
       "\n",
       "                                                     2  \n",
       "0     This blackout was largely preventable ,  Ener...  \n",
       "1    The natural gas producer and marketer said the...  \n",
       "2    The other 18 people in the building , includin...  \n",
       "3    Indeed , the Harry Potter series stands in a c...  \n",
       "4    Families stuck on the highway were being urged...  \n",
       "..                                                 ...  \n",
       "944  Further back , Sen. Bob Graham of Florida repo...  \n",
       "945  Micron 's numbers also marked the first quarte...  \n",
       "946   The momentum in the marketplace continues to ...  \n",
       "947  Keanu Reeves and Hugo Weaving in a scene from ...  \n",
       "948  Those unfair sales have damaged the US industr...  \n",
       "\n",
       "[949 rows x 3 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "b931c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting column names for test and training set\n",
    "df_train.columns = [\"iter\",\"sent1\",\"sent2\",\"gold_score\"]\n",
    "df_test.columns = [\"iter\",\"sent1\",\"sent2\",\"gold_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "48487b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter          0\n",
      "sent1         0\n",
      "sent2         0\n",
      "gold_score    0\n",
      "dtype: int64\n",
      "iter          0\n",
      "sent1         0\n",
      "sent2         0\n",
      "gold_score    0\n",
      "dtype: int64\n",
      "(3850, 4)\n",
      "(699, 4)\n"
     ]
    }
   ],
   "source": [
    "#remove all rows with null values\n",
    "df_train = df_train.dropna()\n",
    "print(df_train.isnull().sum())\n",
    "df_test = df_test.dropna()\n",
    "print(df_test.isnull().sum())\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "0dbc61bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data target names: [1. 0.]\n",
      "Test data target names: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#possible target names \n",
    "print(\"Train data target names: {}\".format(df_train[\"gold_score\"].unique()))\n",
    "print(\"Test data target names: {}\".format(df_test[\"gold_score\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "70945d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training dataset\n",
    "df_train['sent1']=df_train['sent1'].astype('string')\n",
    "df_train['sent2']=df_train['sent2'].astype('string')\n",
    "df_train['sent1'] = df_train['sent1'].str.lower()\n",
    "df_train['sent2'] = df_train['sent2'].str.lower()\n",
    "#Test dataset\n",
    "df_test['sent1']=df_test['sent1'].astype('string')\n",
    "df_test['sent2']=df_test['sent2'].astype('string')\n",
    "df_test['sent1'] = df_test['sent1'].str.lower()\n",
    "df_test['sent2'] = df_test['sent2'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "986aed74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data target names: [1. 0.]\n",
      "Test data target names: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data target names: {}\".format(df_train[\"gold_score\"].unique()))\n",
    "print(\"Test data target names: {}\".format(df_test[\"gold_score\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "0af70a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter           object\n",
      "sent1          string\n",
      "sent2          string\n",
      "gold_score    float64\n",
      "dtype: object\n",
      "iter           object\n",
      "sent1          string\n",
      "sent2          string\n",
      "gold_score    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "8e10fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "df_train['sent1'] = df_train['sent1'].str.replace(\",\",\"\")\n",
    "df_train['sent2'] = df_train['sent2'].str.replace(\",\",\"\")\n",
    "#Testing\n",
    "df_test['sent1'] = df_test['sent1'].str.replace(\",\",\"\")\n",
    "df_test['sent2'] = df_test['sent2'].str.replace(\",\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7404b57c",
   "metadata": {},
   "source": [
    "## Feature 1: WordCount difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "fd585b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train.assign(sent1l=lambda x: (x['sent1']))\n",
    "# df_train = df_train.assign(sent2l=lambda x: (x['sent2']))\n",
    "# df_test = df_test.assign(sent1l=lambda x: (x['sent1']))\n",
    "# df_test = df_test.assign(sent2l=lambda x: (x['sent2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "2d37e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sent1l'] = df_train['sent1'].str.split()\n",
    "df_train['sent2l'] = df_train['sent2'].str.split()\n",
    "df_test['sent1l'] = df_test['sent1'].str.split()\n",
    "df_test['sent2l'] = df_test['sent2'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "4e96223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sent1l']=df_train['sent1l'].apply(lambda x: len(x))\n",
    "df_train['sent2l']=df_train['sent2l'].apply(lambda x: len(x))\n",
    "df_test['sent1l']=df_test['sent1l'].apply(lambda x: len(x))\n",
    "df_test['sent2l']=df_test['sent2l'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9db9a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))\n",
    "df_test = df_test.assign(wcd=lambda x: abs((x['sent1l']-x['sent2l'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "83ea6f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>gold_score</th>\n",
       "      <th>sent1l</th>\n",
       "      <th>sent2l</th>\n",
       "      <th>wcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_id_0</td>\n",
       "      <td>local police authorities are treating the expl...</td>\n",
       "      <td>acting new haven police chief francisco ortiz ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_id_1</td>\n",
       "      <td>the report shows that drugs sold in canadian p...</td>\n",
       "      <td>the report shows that drugs sold in canadian p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_id_2</td>\n",
       "      <td>the transition is slated to begin no later tha...</td>\n",
       "      <td>a two-week transition period will begin no lat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_id_3</td>\n",
       "      <td>like viacom  ge -- parent of nbc -- is also se...</td>\n",
       "      <td>like viacom  general electric is seen as a les...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_id_4</td>\n",
       "      <td>last month  62 spanish peacekeepers died when ...</td>\n",
       "      <td>in another disaster  62 spanish peacekeepers w...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>dev_id_719</td>\n",
       "      <td>he is a brother to three-year-old mia  from ka...</td>\n",
       "      <td>winslet  28  has a three-year-old daughter mia...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>dev_id_720</td>\n",
       "      <td>some 175 million shares traded on the big boar...</td>\n",
       "      <td>some 1.6 billion shares traded on the big boar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>dev_id_721</td>\n",
       "      <td>mr berlusconi is accused of bribing judges to ...</td>\n",
       "      <td>mr berlusconi is accused of bribing judges to ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>dev_id_722</td>\n",
       "      <td>he added that those \" are not solely american ...</td>\n",
       "      <td>these are not solely american principles nor ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>dev_id_723</td>\n",
       "      <td>memories also live on of the bloody debacle in...</td>\n",
       "      <td>memories also live on of a bloody debacle in s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           iter                                              sent1  \\\n",
       "0      dev_id_0  local police authorities are treating the expl...   \n",
       "1      dev_id_1  the report shows that drugs sold in canadian p...   \n",
       "2      dev_id_2  the transition is slated to begin no later tha...   \n",
       "3      dev_id_3  like viacom  ge -- parent of nbc -- is also se...   \n",
       "4      dev_id_4  last month  62 spanish peacekeepers died when ...   \n",
       "..          ...                                                ...   \n",
       "698  dev_id_719  he is a brother to three-year-old mia  from ka...   \n",
       "699  dev_id_720  some 175 million shares traded on the big boar...   \n",
       "700  dev_id_721  mr berlusconi is accused of bribing judges to ...   \n",
       "701  dev_id_722  he added that those \" are not solely american ...   \n",
       "702  dev_id_723  memories also live on of the bloody debacle in...   \n",
       "\n",
       "                                                 sent2  gold_score  sent1l  \\\n",
       "0    acting new haven police chief francisco ortiz ...         0.0      18   \n",
       "1    the report shows that drugs sold in canadian p...         1.0      25   \n",
       "2    a two-week transition period will begin no lat...         1.0      14   \n",
       "3    like viacom  general electric is seen as a les...         1.0      25   \n",
       "4    in another disaster  62 spanish peacekeepers w...         1.0      18   \n",
       "..                                                 ...         ...     ...   \n",
       "698  winslet  28  has a three-year-old daughter mia...         0.0      18   \n",
       "699  some 1.6 billion shares traded on the big boar...         0.0      21   \n",
       "700  mr berlusconi is accused of bribing judges to ...         1.0      20   \n",
       "701   these are not solely american principles nor ...         1.0      17   \n",
       "702  memories also live on of a bloody debacle in s...         1.0      23   \n",
       "\n",
       "     sent2l  wcd  \n",
       "0        18    0  \n",
       "1        30    5  \n",
       "2        12    2  \n",
       "3        17    8  \n",
       "4        21    3  \n",
       "..      ...  ...  \n",
       "698      17    1  \n",
       "699      19    2  \n",
       "700      22    2  \n",
       "701      14    3  \n",
       "702      23    0  \n",
       "\n",
       "[699 rows x 7 columns]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5556d",
   "metadata": {},
   "source": [
    "## Feature 2: Fuzzywuzzy ration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "b84baaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import string\n",
    "fuzz.token_sort_ratio(\"this is a test\", \"this is a test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "d5327025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fuzz_ratio'] = df_train.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['fuzz_ratio'] = df_test.apply(lambda row: fuzz.ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "37947318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['fuzz_token_sort_ratio'] = df_train.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "df_test['fuzz_token_sort_ratio'] = df_test.apply(lambda row: fuzz.token_sort_ratio(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4f582d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>gold_score</th>\n",
       "      <th>sent1l</th>\n",
       "      <th>sent2l</th>\n",
       "      <th>wcd</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>the democratic candidates also began announcin...</td>\n",
       "      <td>the democratic candidates also began announcin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>the woman was exposed to the sars virus while ...</td>\n",
       "      <td>the woman was exposed to the sars virus while ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>he said the problem needs to be corrected befo...</td>\n",
       "      <td>he said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>a representative for phoenix-based u-haul decl...</td>\n",
       "      <td>anthony citrano  a representative for whenu  d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>the biggest threat to order seemed to be looti...</td>\n",
       "      <td>the biggest threat to order seemed to be looti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>axelrod died in his sleep of heart failure  sa...</td>\n",
       "      <td>axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>saddam 's other son  odai  surrendered friday ...</td>\n",
       "      <td>hussein 's other son  uday  surrendered yester...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>if senator clinton does decide to run in 2008 ...</td>\n",
       "      <td>if mrs clinton does decide to contest the 2008...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>the iranian refugee who sewed up his eyes  lip...</td>\n",
       "      <td>an iranian kurd who stitched up his eyes  lips...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3871</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>gemstar 's shares gathered up 2.6 percent  add...</td>\n",
       "      <td>gemstar shares moved higher on the news  closi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3850 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               iter                                              sent1  \\\n",
       "0        train_id_0  the democratic candidates also began announcin...   \n",
       "1        train_id_1  the woman was exposed to the sars virus while ...   \n",
       "2        train_id_2  he said the problem needs to be corrected befo...   \n",
       "3        train_id_3  a representative for phoenix-based u-haul decl...   \n",
       "4        train_id_4  the biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "3867  train_id_4072  axelrod died in his sleep of heart failure  sa...   \n",
       "3868  train_id_4073  saddam 's other son  odai  surrendered friday ...   \n",
       "3869  train_id_4074  if senator clinton does decide to run in 2008 ...   \n",
       "3870  train_id_4075  the iranian refugee who sewed up his eyes  lip...   \n",
       "3871  train_id_4076  gemstar 's shares gathered up 2.6 percent  add...   \n",
       "\n",
       "                                                  sent2  gold_score  sent1l  \\\n",
       "0     the democratic candidates also began announcin...         1.0      23   \n",
       "1     the woman was exposed to the sars virus while ...         1.0      33   \n",
       "2     he said the prob lem needs to be corrected bef...         1.0      19   \n",
       "3     anthony citrano  a representative for whenu  d...         0.0      19   \n",
       "4     the biggest threat to order seemed to be looti...         1.0      25   \n",
       "...                                                 ...         ...     ...   \n",
       "3867  axelrod died of heart failure while asleep at ...         1.0      14   \n",
       "3868  hussein 's other son  uday  surrendered yester...         1.0      21   \n",
       "3869  if mrs clinton does decide to contest the 2008...         1.0      26   \n",
       "3870  an iranian kurd who stitched up his eyes  lips...         1.0      29   \n",
       "3871  gemstar shares moved higher on the news  closi...         1.0      17   \n",
       "\n",
       "      sent2l  wcd  fuzz_ratio  fuzz_token_sort_ratio  \n",
       "0         25    2          89                     88  \n",
       "1         30    3          98                     97  \n",
       "2         17    2          90                     87  \n",
       "3         13    6          61                     61  \n",
       "4         29    4          79                     79  \n",
       "...      ...  ...         ...                    ...  \n",
       "3867      18    4          72                     80  \n",
       "3868      21    0          90                     81  \n",
       "3869      27    1          90                     88  \n",
       "3870      23    6          68                     68  \n",
       "3871      17    0          57                     59  \n",
       "\n",
       "[3850 rows x 9 columns]"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2a479",
   "metadata": {},
   "source": [
    "## Feature 3: Bleu score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "a6a3dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "e17442f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['bleu_score'] = df_train.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4), axis = 1)\n",
    "df_test['bleu_score'] = df_test.apply(lambda row: sentence_bleu(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation)),smoothing_function=SmoothingFunction().method4),axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "cd18e641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iter</th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>gold_score</th>\n",
       "      <th>sent1l</th>\n",
       "      <th>sent2l</th>\n",
       "      <th>wcd</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "      <th>bleu_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>the woman was exposed to the sars virus while ...</td>\n",
       "      <td>the woman was exposed to the sars virus while ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>0.004939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>he said the problem needs to be corrected befo...</td>\n",
       "      <td>he said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>0.008011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>a representative for phoenix-based u-haul decl...</td>\n",
       "      <td>anthony citrano  a representative for whenu  d...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>61</td>\n",
       "      <td>0.008799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>the biggest threat to order seemed to be looti...</td>\n",
       "      <td>the biggest threat to order seemed to be looti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>0.004822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_5</td>\n",
       "      <td>crews worked to install a new culvert and prep...</td>\n",
       "      <td>crews worked to install a new culvert and repa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>82</td>\n",
       "      <td>0.006559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>axelrod died in his sleep of heart failure  sa...</td>\n",
       "      <td>axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0.006853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3867</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>saddam 's other son  odai  surrendered friday ...</td>\n",
       "      <td>hussein 's other son  uday  surrendered yester...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>0.006430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3868</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>if senator clinton does decide to run in 2008 ...</td>\n",
       "      <td>if mrs clinton does decide to contest the 2008...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>0.005049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3869</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>the iranian refugee who sewed up his eyes  lip...</td>\n",
       "      <td>an iranian kurd who stitched up his eyes  lips...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>0.006053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3870</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>gemstar 's shares gathered up 2.6 percent  add...</td>\n",
       "      <td>gemstar shares moved higher on the news  closi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.008744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3849 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               iter                                              sent1  \\\n",
       "0        train_id_1  the woman was exposed to the sars virus while ...   \n",
       "1        train_id_2  he said the problem needs to be corrected befo...   \n",
       "2        train_id_3  a representative for phoenix-based u-haul decl...   \n",
       "3        train_id_4  the biggest threat to order seemed to be looti...   \n",
       "4        train_id_5  crews worked to install a new culvert and prep...   \n",
       "...             ...                                                ...   \n",
       "3866  train_id_4072  axelrod died in his sleep of heart failure  sa...   \n",
       "3867  train_id_4073  saddam 's other son  odai  surrendered friday ...   \n",
       "3868  train_id_4074  if senator clinton does decide to run in 2008 ...   \n",
       "3869  train_id_4075  the iranian refugee who sewed up his eyes  lip...   \n",
       "3870  train_id_4076  gemstar 's shares gathered up 2.6 percent  add...   \n",
       "\n",
       "                                                  sent2  gold_score  sent1l  \\\n",
       "0     the woman was exposed to the sars virus while ...         1.0      33   \n",
       "1     he said the prob lem needs to be corrected bef...         1.0      19   \n",
       "2     anthony citrano  a representative for whenu  d...         0.0      19   \n",
       "3     the biggest threat to order seemed to be looti...         1.0      25   \n",
       "4     crews worked to install a new culvert and repa...         0.0      29   \n",
       "...                                                 ...         ...     ...   \n",
       "3866  axelrod died of heart failure while asleep at ...         1.0      14   \n",
       "3867  hussein 's other son  uday  surrendered yester...         1.0      21   \n",
       "3868  if mrs clinton does decide to contest the 2008...         1.0      26   \n",
       "3869  an iranian kurd who stitched up his eyes  lips...         1.0      29   \n",
       "3870  gemstar shares moved higher on the news  closi...         1.0      17   \n",
       "\n",
       "      sent2l  wcd  fuzz_token_sort_ratio  bleu_score  \n",
       "0         30    3                     97    0.004939  \n",
       "1         17    2                     87    0.008011  \n",
       "2         13    6                     61    0.008799  \n",
       "3         29    4                     79    0.004822  \n",
       "4         21    8                     82    0.006559  \n",
       "...      ...  ...                    ...         ...  \n",
       "3866      18    4                     80    0.006853  \n",
       "3867      21    0                     81    0.006430  \n",
       "3868      27    1                     88    0.005049  \n",
       "3869      23    6                     68    0.006053  \n",
       "3870      17    0                     59    0.008744  \n",
       "\n",
       "[3849 rows x 9 columns]"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d127191",
   "metadata": {},
   "source": [
    "## Feature 4: Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "449385ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# count_vect = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# t = cosine_similarity(trsfm[0:1], trsfm)\n",
    "# print(t[0][1])\n",
    "\n",
    "# trsfm=vectorizer.fit_transform(corpus)\n",
    "\n",
    "\n",
    "# corpus = [Document1,Document2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "875a875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<2x23 sparse matrix of type '<class 'numpy.int64'>'\n",
      " \twith 46 stored elements in Compressed Sparse Row format>\n",
      " <2x19 sparse matrix of type '<class 'numpy.int64'>'\n",
      " \twith 31 stored elements in Compressed Sparse Row format>\n",
      " <2x19 sparse matrix of type '<class 'numpy.int64'>'\n",
      " \twith 27 stored elements in Compressed Sparse Row format> ...\n",
      " <2x27 sparse matrix of type '<class 'numpy.int64'>'\n",
      " \twith 49 stored elements in Compressed Sparse Row format>\n",
      " <2x32 sparse matrix of type '<class 'numpy.int64'>'\n",
      " \twith 46 stored elements in Compressed Sparse Row format>\n",
      " <2x19 sparse matrix of type '<class 'numpy.int64'>'\n",
      " \twith 26 stored elements in Compressed Sparse Row format>]\n"
     ]
    }
   ],
   "source": [
    "# trsfm=vectorizer.fit_transform(corpus)\n",
    "# X_train_counts = df_train.apply(lambda row: count_vect.fit_transform([row['sent1'], row['sent2']]), axis = 1)\n",
    "# X_train_counts=np.array(X_train_counts)\n",
    "# print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "6f871533",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3849, 1), indices imply (2, 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1674\u001b[0m                 blocks = [\n\u001b[0;32m-> 1675\u001b[0;31m                     make_block(\n\u001b[0m\u001b[1;32m   1676\u001b[0m                         \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2742\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 1, placement implies 19",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-380-bc71c1f0bf10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_counts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount_vect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sentence 1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Sentence 3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# For data is list-like, or Iterable (will consume into list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[0;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mblock_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   1685\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"values\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1687\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (3849, 1), indices imply (2, 19)"
     ]
    }
   ],
   "source": [
    "# pd.DataFrame(X_train_counts,columns=count_vect.get_feature_names(),index=['Sentence 1','Sentence 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "6dc058d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         (0, 16)\\t3\\n  (0, 21)\\t1\\n  (0, 19)\\t2\\n  (0...\n",
      "1         (0, 8)\\t1\\n  (0, 14)\\t1\\n  (0, 17)\\t2\\n  (0,...\n",
      "2         (0, 14)\\t1\\n  (0, 7)\\t1\\n  (0, 12)\\t1\\n  (0,...\n",
      "3         (0, 21)\\t3\\n  (0, 3)\\t1\\n  (0, 23)\\t1\\n  (0,...\n",
      "4         (0, 4)\\t1\\n  (0, 25)\\t1\\n  (0, 22)\\t2\\n  (0,...\n",
      "                              ...                        \n",
      "3866      (0, 3)\\t2\\n  (0, 5)\\t1\\n  (0, 10)\\t1\\n  (0, ...\n",
      "3867      (0, 13)\\t1\\n  (0, 11)\\t1\\n  (0, 14)\\t1\\n  (0...\n",
      "3868      (0, 14)\\t1\\n  (0, 21)\\t1\\n  (0, 6)\\t1\\n  (0,...\n",
      "3869      (0, 27)\\t2\\n  (0, 16)\\t1\\n  (0, 21)\\t1\\n  (0...\n",
      "3870      (0, 8)\\t1\\n  (0, 15)\\t1\\n  (0, 7)\\t1\\n  (0, ...\n",
      "Length: 3849, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# print(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "4a2ba5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06435000938807836\n"
     ]
    }
   ],
   "source": [
    "# corpus = [Document1,Document3]\n",
    "\n",
    "# X_train_counts = count_vect.fit_transform(corpus)\n",
    "\n",
    "# pd.DataFrame(X_train_counts.toarray(),columns=count_vect.get_feature_names(),index=['Document 1','Document 3'])\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# trsfm=vectorizer.fit_transform(corpus)\n",
    "# pd.DataFrame(trsfm.toarray(),columns=vectorizer.get_feature_names(),index=['Document 1','Document 3'])\n",
    "\n",
    "# t = cosine_similarity(trsfm[0:1], trsfm)\n",
    "\n",
    "# print(t[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "0e26b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document3 = \"\"\"no no fheym sad.\"\"\"\n",
    "\n",
    "# corpus = [\"Document1\",\"Docume?nt3\"]\n",
    "# X_train_counts = count_vect.fit_transform(corpus)\n",
    "\n",
    "# pd.DataFrame(X_train_counts.toarray(),columns=count_vect.get_feature_names(),index=['Document 1','Document 3'])\n",
    "\n",
    "# vectorizer = TfidfVectorizer()\n",
    "\n",
    "# trsfm=vectorizer.fit_transform(corpus)\n",
    "# pd.DataFrame(trsfm.toarray(),columns=vectorizer.get_feature_names(),index=['Document 1','Document 3'])\n",
    "\n",
    "# print(cosine_similarity(trsfm[0:1], trsfm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "0c63c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_vectors = df_train.apply(lambda row: vectorizer.fit_transform(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n",
    "# df_test_vectors = df_test.apply(lambda row: vectorizer.fit_transform(row['sent1'].translate(str.maketrans('', '', string.punctuation)), row['sent2'].translate(str.maketrans('', '', string.punctuation))), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e732b60b",
   "metadata": {},
   "source": [
    "## Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "564e0df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter                      object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "gold_score               float64\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "bleu_score               float64\n",
      "dtype: object\n",
      "iter                      object\n",
      "sent1                     string\n",
      "sent2                     string\n",
      "gold_score               float64\n",
      "sent1l                     int64\n",
      "sent2l                     int64\n",
      "wcd                        int64\n",
      "fuzz_token_sort_ratio      int64\n",
      "bleu_score               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.dtypes)\n",
    "print(df_test.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "e146e362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_val: (3849, 4), test: (698, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(columns=['iter','sent1','sent2','gold_score','sent1l','sent2l']).values\n",
    "X_test = df_test.drop(columns=['iter','sent1','sent2','gold_score','sent1l','sent2l']).values\n",
    "y_train = df_train['gold_score'].values\n",
    "y_test =df_test['gold_score'].values\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "# X_train_val = X_train_val.reshape(-1,1)\n",
    "# X_test = X_test.reshape(-1,1)\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_test = normalizer.transform(X_test)\n",
    "print(\"train_val: {}, test: {}\".format(X_train.shape, X_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c8cc6",
   "metadata": {},
   "source": [
    "## Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "5ac45fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.622, recall: 0.926, precision: 0.577, f1: 0.711,\n"
     ]
    }
   ],
   "source": [
    "# retrain the model\n",
    "clf = LogisticRegression(penalty='l2', solver='lbfgs')\n",
    "clf.fit(X_train_val, y_train_val)\n",
    "\n",
    "# evaluate the model on the testing set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"accuracy: {:.3f}, recall: {:.3f}, precision: {:.3f}, f1: {:.3f},\".format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c5175",
   "metadata": {},
   "source": [
    "## SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "c566495e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.623, recall: 0.946, precision: 0.576, f1: 0.716,\n"
     ]
    }
   ],
   "source": [
    "# retrain the model\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the testing set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "print(\"accuracy: {:.3f}, recall: {:.3f}, precision: {:.3f}, f1: {:.3f},\".format(acc, recall, precision, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e71b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "\n",
    "num_train_val = X_train.shape[0] \n",
    "\n",
    "# shuffle the index of samples in the train_val set\n",
    "index_of_samples = np.arange(num_train_val) \n",
    "shuffle(index_of_samples)\n",
    "\n",
    "# split the index of the train_valid set into 5 folds\n",
    "index_of_folds = index_of_samples.reshape(folds, -1)\n",
    "print(index_of_folds)\n",
    "\n",
    "regularization_coefficient = [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10.0,20.0,50.0,100.0]\n",
    "\n",
    "best_acc = 0.0\n",
    "best_reg = 0.0\n",
    "\n",
    "for reg in regularization_coefficient:\n",
    "    \n",
    "    # 3-fold cross-validation\n",
    "    sum_acc = 0.0\n",
    "    for fold in range(folds):\n",
    "        \n",
    "        index_of_folds_temp = index_of_folds.copy()\n",
    "        \n",
    "        valid_index = index_of_folds_temp[fold,:].reshape(-1) #get the index of the validation set\n",
    "        train_index = np.delete(index_of_folds_temp, fold, 0).reshape(-1) #get the index of the training set\n",
    "        \n",
    "#         # training set\n",
    "        X_train = X_train[train_index]\n",
    "        y_train = y_train[train_index]\n",
    "        \n",
    "        # validation set\n",
    "        X_valid = X_train[valid_index]\n",
    "        y_valid = y_train[valid_index]\n",
    "                \n",
    "        # build the model with different hyperparameters\n",
    "        clf = LogisticRegression(penalty='l2', C=reg, solver='lbfgs')\n",
    "        \n",
    "        #train the model with the training set\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc = accuracy_score(y_valid, y_valid_pred)\n",
    "        \n",
    "        sum_acc += acc\n",
    "    \n",
    "    cur_acc = sum_acc / folds\n",
    "    \n",
    "    print(\"reg_coeff: {}, acc: {:.3f}\".format(1.0/reg, cur_acc))\n",
    "    \n",
    "    # store the best hyperparameter\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        best_reg = reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52790737",
   "metadata": {},
   "source": [
    "Pre-processing: Remove double quotes that are not in pair. If possible create pairs correctly\n",
    "df = pd.read_csv('data_reading_test.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e36321",
   "metadata": {},
   "source": [
    "Open and load the dataset after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.50, shuffle=False)\n",
    "print(\"Train data target names: {}\".format(df_train[3].unique()))\n",
    "\n",
    "print('Size of training sample: {}'.format(len(df_train)))\n",
    "print('Size of testting samples: {}'.format(len(df_test)))\n",
    "print(df_train.shape)\n",
    "\n",
    "#TF-IDF representation for each document\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# to_vectorize = df_train.drop(columns=[0,3])\n",
    "# print(to_vectorize)\n",
    "# test = vectorizer.fit(to_vectorize2)\n",
    "# print(test)\n",
    "# data_train_vectors1 = vectorizer.fit_transform(df_train[1])\n",
    "# data_train_vectors2 = vectorizer.fit_transform(df_train[2])\n",
    "# data_test_vectors = vectorizer.transform(df_test[1])\n",
    "\n",
    "# print(data_train_vectors.shape, data_test_vectors.shape)\n",
    "df_train_1 = vectorizer.fit_transform(df_train[1])\n",
    "df_train_2 = vectorizer.fit_transform(df_train[2])\n",
    "df_test_1 = vectorizer.fit_transform(df_test[1])\n",
    "df_test_2 = vectorizer.fit_transform(df_test[2])\n",
    "# df_train[1] = df_train[1].replace(to_replace=\"\\t\", value=\" \", regex=True)\n",
    "# df_test =  vectorizer.fit_transform(df[2])\n",
    "print(df_train_1.shape)\n",
    "print(df_train_2.shape)\n",
    "print(df_test_1.shape)\n",
    "print(df_test_2.shape)\n",
    "# print(df_train_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "f43b03af1b6c7d2647a9c83c0faa395d808984b869aa737ec4f7298e40a0df4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
